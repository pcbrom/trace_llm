{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Second Step: Zero-Shot Semantic Interval Rubric with model-internal evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "\n",
    "# Load .env\n",
    "dotenv_path = \"/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/.env\"\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Retrieve API keys\n",
    "openai_api_key     = os.getenv(\"OPENAI_API_KEY\")\n",
    "claude_api_key     = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "xai_api_key        = os.getenv(\"XAI_API_KEY\")\n",
    "deepseek_api_key   = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "# Configure clients\n",
    "client_gpt     = OpenAI(api_key=openai_api_key)\n",
    "client_claude  = anthropic.Anthropic(api_key=claude_api_key)\n",
    "client_grok    = OpenAI(api_key=xai_api_key, base_url=\"https://api.x.ai/v1\")\n",
    "client_ds      = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# Registry of supported models\n",
    "models = {\n",
    "    'model_gpt_4o_mini': {'alias': '4o-mini', 'model': 'gpt-4o-mini', 'client': client_gpt},\n",
    "    'model_gpt_41_nano': {'alias': '4.1-nano', 'model': 'gpt-4.1-nano', 'client': client_gpt},\n",
    "    'model_claude_35_haiku': {'alias': '3-haiku', 'model': 'claude-3-5-haiku-latest', 'client': client_claude    },\n",
    "    'model_grok_3_mini_beta': {'alias': 'grok-3-mini', 'model': 'grok-3-mini-beta', 'client': client_grok},\n",
    "    'model_ds_v3': {'alias': 'ds-v3', 'model': 'deepseek-chat', 'client': client_ds}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_two(model_name, prompt):\n",
    "    model_config = models.get(model_name)\n",
    "    if not model_config:\n",
    "        raise ValueError(f\"Model '{model_name}' not found in the 'models' dictionary.\")\n",
    "\n",
    "    client = model_config['client']\n",
    "    model = model_config['model']\n",
    "\n",
    "    if isinstance(client, OpenAI):\n",
    "        response = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        generated_text = response.choices[0].message.content\n",
    "    \n",
    "    elif isinstance(client, anthropic.Anthropic):\n",
    "        response = client.messages.create(model=model, max_tokens=1000, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        generated_text = response.content[0].text\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported client type.\")\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "def step_two_recovered(model_name, prompt):\n",
    "    # Extract model identifier from the model name\n",
    "    model = model_name.split('_', 1)[-1]\n",
    "    model_config = model_name\n",
    "    if not model_config:\n",
    "        raise ValueError(f\"Model '{model_name}' not found in the 'models' dictionary.\")\n",
    "\n",
    "    # Assign the appropriate client and model based on the model name\n",
    "    if model_name == 'model_gpt_4o_mini':\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        client = OpenAI(api_key=openai_api_key)\n",
    "        model = 'gpt-4o-mini'\n",
    "        \n",
    "    elif model_name == 'model_gpt_41_nano':\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        client = OpenAI(api_key=openai_api_key)\n",
    "        model = 'gpt-4.1-nano'\n",
    "        \n",
    "    elif model_name == 'model_claude_35_haiku':\n",
    "        claude_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        client = anthropic.Anthropic(api_key=claude_api_key)\n",
    "        model = 'claude-3-5-haiku-latest'\n",
    "        \n",
    "    elif model_name == 'model_grok_3_mini_beta':\n",
    "        xai_api_key = os.getenv(\"XAI_API_KEY\")\n",
    "        client = OpenAI(api_key=xai_api_key, base_url=\"https://api.x.ai/v1\")\n",
    "        model = 'grok-3-mini-beta'\n",
    "\n",
    "    elif model_name == 'model_ds_v3':\n",
    "        deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "        client = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com\")\n",
    "        model = 'deepseek-chat'\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    # Generate response based on client type\n",
    "    if isinstance(client, OpenAI):\n",
    "        response = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        generated_text = response.choices[0].message.content\n",
    "    elif isinstance(client, anthropic.Anthropic):\n",
    "        response = client.messages.create(model=model, max_tokens=1000, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        generated_text = response.content[0].text\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported client type.\")\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10125, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>item</th>\n",
       "      <th>answer</th>\n",
       "      <th>r</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>hit</th>\n",
       "      <th>model_alternative_answer</th>\n",
       "      <th>hit_alternative</th>\n",
       "      <th>alternative_response</th>\n",
       "      <th>justification</th>\n",
       "      <th>extra_text</th>\n",
       "      <th>CoT</th>\n",
       "      <th>cot_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>model_gpt_4o_mini</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Body weight is significantly affected by envir...</td>\n",
       "      <td></td>\n",
       "      <td>1. Body weight is influenced by both genetics ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>model_gpt_4o_mini</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Body weight is strongly affected by environmen...</td>\n",
       "      <td></td>\n",
       "      <td>1. To determine which trait is most influenced...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>model_gpt_4o_mini</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Body weight is the trait most significantly in...</td>\n",
       "      <td></td>\n",
       "      <td>1. Body weight is influenced by both genetics ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>model_gpt_4o_mini</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Body weight is heavily influenced by environme...</td>\n",
       "      <td></td>\n",
       "      <td>1. Body weight can be influenced by diet, phys...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>model_gpt_4o_mini</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Body weight is the trait most affected by envi...</td>\n",
       "      <td></td>\n",
       "      <td>1. Body weight can be heavily influenced by en...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                               item answer  r  \\\n",
       "0    ARC  Question: Which of the following traits is mos...      A  0   \n",
       "1    ARC  Question: Which of the following traits is mos...      A  1   \n",
       "2    ARC  Question: Which of the following traits is mos...      A  2   \n",
       "3    ARC  Question: Which of the following traits is mos...      A  3   \n",
       "4    ARC  Question: Which of the following traits is mos...      A  4   \n",
       "\n",
       "               model prompt_type model_answer  hit model_alternative_answer  \\\n",
       "0  model_gpt_4o_mini         cot            A    1                        A   \n",
       "1  model_gpt_4o_mini         cot            A    1                        A   \n",
       "2  model_gpt_4o_mini         cot            A    1                        A   \n",
       "3  model_gpt_4o_mini         cot            A    1                        A   \n",
       "4  model_gpt_4o_mini         cot            A    1                        A   \n",
       "\n",
       "   hit_alternative alternative_response  \\\n",
       "0                1                        \n",
       "1                1                        \n",
       "2                1                        \n",
       "3                1                        \n",
       "4                1                        \n",
       "\n",
       "                                       justification extra_text  \\\n",
       "0  Body weight is significantly affected by envir...              \n",
       "1  Body weight is strongly affected by environmen...              \n",
       "2  Body weight is the trait most significantly in...              \n",
       "3  Body weight is heavily influenced by environme...              \n",
       "4  Body weight is the trait most affected by envi...              \n",
       "\n",
       "                                                 CoT cot_steps  \n",
       "0  1. Body weight is influenced by both genetics ...       5.0  \n",
       "1  1. To determine which trait is most influenced...       7.0  \n",
       "2  1. Body weight is influenced by both genetics ...       5.0  \n",
       "3  1. Body weight can be influenced by diet, phys...       4.0  \n",
       "4  1. Body weight can be heavily influenced by en...       5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv('data/tidydata2cmr.csv').fillna('')\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Depth of Reasoning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a professional evaluator. Your task is to assess the Depth of Reasoning of the extracted content.Assess the complexity and structure of the reasoning.\n",
      "\n",
      "Input:\n",
      "\n",
      "- Item: Question: Which of the following traits is most influenced by the environment?\n",
      "Choices:\n",
      "A. Body weight\n",
      "B. Eye color\n",
      "C. Blood type\n",
      "D. Color blindness\n",
      "- Correct Answer: A\n",
      "\n",
      "- Extracted Answer: A\n",
      "- Extracted Justification: Body weight is significantly affected by environmental factors like diet and activity level, making it the trait most influenced by the environment among the options listed.\n",
      "- Extracted Alternative Response: \n",
      "- Extracted Chain of Thought: 1. Body weight is influenced by both genetics and environmental factors such as diet, physical activity, and lifestyle; thus, it is highly environment-dependent. 2. Eye color is primarily determined by genetics, with minimal environmental influence. 3. Blood type is genetically determined and does not change due to environmental factors. 4. Color blindness is a genetic trait inherited from parents and is unaffected by environmental factors. 5. Therefore, among the options, body weight is most influenced by the environment.\n",
      "\n",
      "Score from 0 (no reasoning) to 10 (multi-step, layered inference).\n",
      "\n",
      "Refer to the following rubric:\n",
      "\n",
      "Score Interval: (9,10] | Multi-step, layered reasoning with strong inferential structure.\n",
      "Score Interval: (7,9]  | Sound and structured reasoning with some complexity.\n",
      "Score Interval: (5,7]  | Basic logical sequence with minimal elaboration.\n",
      "Score Interval: (3,5]  | Shallow reasoning with gaps or simplifications.\n",
      "Score Interval: (1,3]  | Fragmented logic or one-step heuristic answer.\n",
      "Score Interval: [0,1]  | No reasoning trace or incoherent rationale.\n",
      "\n",
      "Based on this rubric, assign a score from 0 to 10 for Depth of Reasoning\n",
      "Return ONLY the following JSON:\n",
      "\n",
      "```json\n",
      "{\n",
      "depth_of_reasoning: <float>,\n",
      "depth_of_reasoning_justification: <explanation of reasoning structure>\n",
      "}\n",
      "```\n",
      "\n",
      "Ensure the JSON is parseable by a standard JSON parser (double quotes for keys, no trailing commas).\n"
     ]
    }
   ],
   "source": [
    "def build_depth_of_reasoning_prompt(row):\n",
    "    prompt = (\n",
    "        \"You are a professional evaluator. Your task is to assess the Depth of Reasoning of the extracted content.\"\n",
    "        \"Assess the complexity and structure of the reasoning.\\n\\n\"\n",
    "        \"Input:\\n\\n\"\n",
    "        \"- Item: \" f\"{row[\"item\"]}\\n\"\n",
    "        \"- Correct Answer: \" f\"{row[\"answer\"]}\\n\\n\"\n",
    "        \"- Extracted Answer: \" f\"{row[\"model_alternative_answer\"]}\\n\"\n",
    "        \"- Extracted Justification: \" f\"{row[\"justification\"]}\\n\"\n",
    "        \"- Extracted Alternative Response: \" f\"{row[\"alternative_response\"]}\\n\"\n",
    "        \"- Extracted Chain of Thought: \" f\"{row[\"CoT\"]}\\n\\n\"\n",
    "\n",
    "        \"Score from 0 (no reasoning) to 10 (multi-step, layered inference).\\n\\n\"\n",
    "\n",
    "        \"Refer to the following rubric:\\n\\n\"\n",
    "        \"Score Interval: (9,10] | Multi-step, layered reasoning with strong inferential structure.\\n\"\n",
    "        \"Score Interval: (7,9]  | Sound and structured reasoning with some complexity.\\n\"\n",
    "        \"Score Interval: (5,7]  | Basic logical sequence with minimal elaboration.\\n\"\n",
    "        \"Score Interval: (3,5]  | Shallow reasoning with gaps or simplifications.\\n\"\n",
    "        \"Score Interval: (1,3]  | Fragmented logic or one-step heuristic answer.\\n\"\n",
    "        \"Score Interval: [0,1]  | No reasoning trace or incoherent rationale.\\n\\n\"\n",
    "\n",
    "        \"Based on this rubric, assign a score from 0 to 10 for Depth of Reasoning\\n\"\n",
    "        \"Return ONLY the following JSON:\\n\\n\"\n",
    "        \n",
    "        \"```json\\n\"\n",
    "        \"{\\n\"\n",
    "            \"depth_of_reasoning: <float>,\\n\"\n",
    "            \"depth_of_reasoning_justification: <explanation of reasoning structure>\\n\"\n",
    "        \"}\\n\"\n",
    "        \"```\\n\\n\"\n",
    "        \"Ensure the JSON is parseable by a standard JSON parser (double quotes for keys, no trailing commas).\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "i=0\n",
    "row = df.iloc[i]\n",
    "print(build_depth_of_reasoning_prompt(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique model names from the dataframe\n",
    "unique_models = df['model'].unique()\n",
    "\n",
    "# Prepare subsets of the dataframe for each target model\n",
    "subsets_with_results = {\n",
    "    model: df[df['model'] == model].copy()\n",
    "    for model in unique_models\n",
    "}\n",
    "\n",
    "# Function to evaluate a pair of models (evaluator and target)\n",
    "def evaluate_pair(evaluator_model, target_model):\n",
    "    subset = subsets_with_results[target_model]\n",
    "    generated = []\n",
    "\n",
    "    # Iterate over each row in the subset with progress bar\n",
    "    for _, row in tqdm(subset.iterrows(),\n",
    "                       total=len(subset),\n",
    "                       desc=f\"{evaluator_model} → {target_model}\",\n",
    "                       leave=False):\n",
    "        # Build prompt for depth of reasoning assessment\n",
    "        prompt = build_depth_of_reasoning_prompt(row)\n",
    "        # Generate response using step_two function\n",
    "        generated_text = step_two(evaluator_model, prompt)\n",
    "        generated.append(generated_text)\n",
    "\n",
    "    # Store generated responses in the corresponding column\n",
    "    subsets_with_results[target_model][f'step2_{evaluator_model}'] = generated\n",
    "\n",
    "# Create list of tasks for all model pairs (evaluator vs target)\n",
    "tasks = [\n",
    "    (evaluator, target)\n",
    "    for evaluator in unique_models\n",
    "    for target in unique_models\n",
    "]\n",
    "\n",
    "# Execute evaluation tasks in parallel using ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [\n",
    "        executor.submit(evaluate_pair, evaluator, target)\n",
    "        for evaluator, target in tasks\n",
    "    ]\n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# Save the results for each target model to CSV files\n",
    "for target_model, df_result in subsets_with_results.items():\n",
    "    df_result.to_csv(f\"data/step2/depth_of_reasoning_{target_model}.csv\", index=False)\n",
    "    print(f\"Saved: depth_of_reasoning_{target_model}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique models from the dataframe\n",
    "unique_models = df['model'].unique()\n",
    "\n",
    "# Create subsets of the dataframe for each target model\n",
    "subsets_with_results = {\n",
    "    model: df[df['model'] == model].copy()\n",
    "    for model in unique_models\n",
    "}\n",
    "\n",
    "# List of missing model pairs (evaluator → target)\n",
    "missing_pairs = [\n",
    "    (\"model_gpt_4o_mini\", \"model_gpt_41_nano\"),\n",
    "    (\"model_gpt_4o_mini\", \"model_ds_v3\"),\n",
    "    (\"model_gpt_4o_mini\", \"model_gpt_4o_mini\"),\n",
    "    (\"model_gpt_41_nano\", \"model_claude_35_haiku\"),\n",
    "    (\"model_claude_35_haiku\", \"model_gpt_4o_mini\"),\n",
    "    (\"model_gpt_41_nano\", \"model_gpt_4o_mini\"),\n",
    "    (\"model_gpt_4o_mini\", \"model_claude_35_haiku\"),\n",
    "]\n",
    "\n",
    "# Output directory path\n",
    "output_dir = \"data/step2\"\n",
    "\n",
    "# Main evaluation function for each model pair\n",
    "def evaluate_pair(evaluator_model, target_model):\n",
    "    subset = subsets_with_results[target_model]\n",
    "    generated = []\n",
    "\n",
    "    print(f\"\\nEvaluating: {evaluator_model} → {target_model} ({len(subset)} items)\")    \n",
    "    for _, row in tqdm(subset.iterrows(), total=len(subset), desc=f\"{evaluator_model} → {target_model}\", leave=False):\n",
    "        try:\n",
    "            # Build prompt for depth of reasoning assessment\n",
    "            prompt = build_depth_of_reasoning_prompt(row)\n",
    "            # Generate response using the recovery function\n",
    "            generated_text = step_two_recovered(evaluator_model, prompt)\n",
    "        except Exception as e:\n",
    "            # Handle errors gracefully\n",
    "            generated_text = f\"ERROR: {str(e)}\"\n",
    "        generated.append(generated_text)\n",
    "\n",
    "    # Store generated responses in the corresponding column\n",
    "    subsets_with_results[target_model][f'step2_{evaluator_model}'] = generated\n",
    "\n",
    "# Execute evaluation for each missing pair in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [\n",
    "        executor.submit(evaluate_pair, evaluator, target)\n",
    "        for evaluator, target in missing_pairs\n",
    "    ]\n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# Save each target model's results as a separate CSV to prevent overwriting\n",
    "for target_model, df_result in subsets_with_results.items():\n",
    "    output_path = os.path.join(output_dir, f\"depth_of_reasoning_{target_model}_recovered.csv\")\n",
    "    df_result.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depth_of_reasoning_model_claude_35_haiku.csv', 'depth_of_reasoning_model_claude_35_haiku_recovered.csv', 'depth_of_reasoning_model_ds_v3.csv', 'depth_of_reasoning_model_ds_v3_recovered.csv', 'depth_of_reasoning_model_gpt_41_nano.csv', 'depth_of_reasoning_model_gpt_41_nano_recovered.csv', 'depth_of_reasoning_model_gpt_4o_mini.csv', 'depth_of_reasoning_model_gpt_4o_mini_recovered.csv', 'depth_of_reasoning_model_grok_3_mini_beta.csv', 'depth_of_reasoning_model_grok_3_mini_beta_recovered.csv']\n"
     ]
    }
   ],
   "source": [
    "# Sort the list of CSV files alphabetically and print\n",
    "step2_dir = \"data/step2\"\n",
    "csv_files = [f for f in os.listdir(step2_dir) if f.endswith('.csv')]\n",
    "csv_files.sort()\n",
    "print(csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 20)\n",
      "(2025, 20)\n",
      "(2025, 20)\n",
      "(2025, 20)\n",
      "(2025, 20)\n",
      "merged_all.csv salvo com shape: (10125, 20)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho para os arquivos CSV\n",
    "step2_dir = 'data/step2/partial'\n",
    "output_dir = 'data/step2/merged'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Lista de arquivos CSV na pasta (excluindo os que já são \"_recovered.csv\")\n",
    "csv_files = [f for f in os.listdir(step2_dir) if f.endswith('.csv') and not f.endswith('_recovered.csv')]\n",
    "\n",
    "# Colunas para realizar o join\n",
    "join_columns = [\n",
    "    'source', 'item', 'answer', 'r', 'model', 'prompt_type',\n",
    "    'model_answer', 'hit', 'model_alternative_answer',\n",
    "    'hit_alternative', 'alternative_response', 'justification',\n",
    "    'extra_text', 'CoT', 'cot_steps'\n",
    "]\n",
    "\n",
    "# Lista para acumular todos os merged_df\n",
    "merged_list = []\n",
    "\n",
    "for filename in csv_files:\n",
    "    original_path = os.path.join(step2_dir, filename)\n",
    "    recovered_path = os.path.join(step2_dir, filename.replace('.csv', '_recovered.csv'))\n",
    "    \n",
    "    if not os.path.exists(recovered_path):\n",
    "        print(f'Arquivo não encontrado: {recovered_path}')\n",
    "        continue\n",
    "\n",
    "    original_df = pd.read_csv(original_path)\n",
    "    recovered_df = pd.read_csv(recovered_path)\n",
    "\n",
    "    merged_df = original_df.merge(recovered_df, how='left', on=join_columns)\n",
    "\n",
    "    # Reorganize columns após 'cot_steps'\n",
    "    cols = list(merged_df.columns)\n",
    "    try:\n",
    "        cot_steps_index = cols.index('cot_steps')\n",
    "        after_cot_steps = cols[cot_steps_index + 1:]\n",
    "        sorted_after_cot_steps = sorted(after_cot_steps)\n",
    "        new_order = cols[:cot_steps_index + 1] + sorted_after_cot_steps\n",
    "        merged_df = merged_df[new_order]\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Salva o arquivo individual\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(merged_df.shape)\n",
    "\n",
    "    # Acumula no merged_all\n",
    "    merged_list.append(merged_df)\n",
    "\n",
    "# Concatena tudo no final\n",
    "merged_all = pd.concat(merged_list, ignore_index=True)\n",
    "merged_all.to_csv(os.path.join(output_dir, 'depth_of_reasoning_model_merged_all.csv'), index=False)\n",
    "print('merged_all.csv salvo com shape:', merged_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Originality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a professional evaluator. Your task is to assess the Originality of the extracted content. Evaluate the degree of abstraction, rephrasing, and lexical and syntactic diversity. Identify signs of prompt echoing, i.e., shallow repetition of lexical elements or structural patterns from the input.\n",
      "\n",
      "Input:\n",
      "- Item: Question: Which of the following traits is most influenced by the environment?\n",
      "Choices:\n",
      "A. Body weight\n",
      "B. Eye color\n",
      "C. Blood type\n",
      "D. Color blindness\n",
      "- Extracted Answer: A\n",
      "- Extracted Justification: Body weight is significantly affected by environmental factors like diet and activity level, making it the trait most influenced by the environment among the options listed.\n",
      "- Extracted Alternative Response: \n",
      "- Extracted Chain of Thought: 1. Body weight is influenced by both genetics and environmental factors such as diet, physical activity, and lifestyle; thus, it is highly environment-dependent. 2. Eye color is primarily determined by genetics, with minimal environmental influence. 3. Blood type is genetically determined and does not change due to environmental factors. 4. Color blindness is a genetic trait inherited from parents and is unaffected by environmental factors. 5. Therefore, among the options, body weight is most influenced by the environment.\n",
      "\n",
      "Also consider the following patterns indicative of originality:\n",
      "- Use of intermediate planning (e.g., step-by-step comments or structured reasoning).\n",
      "- Iterative reasoning or trial-and-error, especially evident in CoT or alternative responses.\n",
      "- Reformulation that departs from both lexical and syntactic structure of the input.\n",
      "- Introduction of new abstractions, analogies, or contextual elements not present in the original item.\n",
      "Flag low originality if responses mirror the input structure or vocabulary, even with surface paraphrasing.\n",
      "\n",
      "Score from 0 (verbatim or generic) to 10 (highly novel or creative).\n",
      "\n",
      "Refer to the following refined rubric:\n",
      "Score Interval: (9,10]  | Highly original and creative phrasing. Demonstrates abstraction, analogies, or planning. No lexical or structural echo from the prompt.\n",
      "Score Interval: (7,9]   | Strong semantic transformation with novel structure or reframing. Limited reuse of form or vocabulary is acceptable if embedded in creative formulation.\n",
      "Score Interval: (5,7]   | Contains some original phrasing or ideas, but retains significant elements from the prompt's syntax or lexicon. Limited abstraction.\n",
      "Score Interval: (3,5]   | Mostly generic or templated response. Moderate echoing in either vocabulary or sentence structure.\n",
      "Score Interval: (1,3]   | Prompt echoing dominates, including structural mimicry. Very low novelty.\n",
      "Score Interval: [0,1]   | Verbatim or near-verbatim reproduction. No abstraction or transformation detected.\n",
      "\n",
      "Based on this rubric, assign a score from 0 to 10 for Originality.\n",
      "Return ONLY the following JSON:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"originality\": <float>,\n",
      "  \"originality_justification\": \"<brief statement of novelty or echoing>\"\n",
      "}\n",
      "```\n",
      "\n",
      "Ensure the JSON is parseable by a standard JSON parser (double quotes for keys, no trailing commas).\n"
     ]
    }
   ],
   "source": [
    "def build_originality_prompt(row):\n",
    "    prompt = (\n",
    "        \"You are a professional evaluator. Your task is to assess the Originality of the extracted content. \"\n",
    "        \"Evaluate the degree of abstraction, rephrasing, and lexical and syntactic diversity. Identify signs of prompt \"\n",
    "        \"echoing, i.e., shallow repetition of lexical elements or structural patterns from the input.\\n\\n\"\n",
    "\n",
    "        \"Input:\\n\"\n",
    "        f\"- Item: {row['item']}\\n\"\n",
    "        f\"- Extracted Answer: {row['model_alternative_answer']}\\n\"\n",
    "        f\"- Extracted Justification: {row['justification']}\\n\"\n",
    "        f\"- Extracted Alternative Response: {row['alternative_response']}\\n\"\n",
    "        f\"- Extracted Chain of Thought: {row['CoT']}\\n\\n\"\n",
    "\n",
    "        \"Also consider the following patterns indicative of originality:\\n\"\n",
    "        \"- Use of intermediate planning (e.g., step-by-step comments or structured reasoning).\\n\"\n",
    "        \"- Iterative reasoning or trial-and-error, especially evident in CoT or alternative responses.\\n\"\n",
    "        \"- Reformulation that departs from both lexical and syntactic structure of the input.\\n\"\n",
    "        \"- Introduction of new abstractions, analogies, or contextual elements not present in the original item.\\n\"\n",
    "        \"Flag low originality if responses mirror the input structure or vocabulary, even with surface paraphrasing.\\n\\n\"\n",
    "\n",
    "        \"Score from 0 (verbatim or generic) to 10 (highly novel or creative).\\n\\n\"\n",
    "        \"Refer to the following refined rubric:\\n\"\n",
    "\n",
    "        \"Score Interval: (9,10]  | Highly original and creative phrasing. Demonstrates abstraction, analogies, or planning. \"\n",
    "        \"No lexical or structural echo from the prompt.\\n\"\n",
    "        \"Score Interval: (7,9]   | Strong semantic transformation with novel structure or reframing. Limited reuse of form or \"\n",
    "        \"vocabulary is acceptable if embedded in creative formulation.\\n\"\n",
    "        \"Score Interval: (5,7]   | Contains some original phrasing or ideas, but retains significant elements from the prompt's \"\n",
    "        \"syntax or lexicon. Limited abstraction.\\n\"\n",
    "        \"Score Interval: (3,5]   | Mostly generic or templated response. Moderate echoing in either vocabulary or sentence structure.\\n\"\n",
    "        \"Score Interval: (1,3]   | Prompt echoing dominates, including structural mimicry. Very low novelty.\\n\"\n",
    "        \"Score Interval: [0,1]   | Verbatim or near-verbatim reproduction. No abstraction or transformation detected.\\n\\n\"\n",
    "\n",
    "        \"Based on this rubric, assign a score from 0 to 10 for Originality.\\n\"\n",
    "        \"Return ONLY the following JSON:\\n\\n\"\n",
    "        \"```json\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"originality\": <float>,\\n'\n",
    "        '  \"originality_justification\": \"<brief statement of novelty or echoing>\"\\n'\n",
    "        \"}\\n\"\n",
    "        \"```\\n\\n\"\n",
    "        \"Ensure the JSON is parseable by a standard JSON parser (double quotes for keys, no trailing commas).\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "i=0\n",
    "row = df.iloc[i]\n",
    "print(build_originality_prompt(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique model names from the dataframe \n",
    "unique_models = df['model'].unique()\n",
    "\n",
    "# Prepare subsets of the dataframe for each target model\n",
    "subsets_with_results = {\n",
    "    model: df[df['model'] == model].copy()\n",
    "    for model in unique_models\n",
    "}\n",
    "\n",
    "# Function to evaluate a pair of models (evaluator and target)\n",
    "def evaluate_pair(evaluator_model, target_model):\n",
    "    subset = subsets_with_results[target_model]\n",
    "    generated = []\n",
    "\n",
    "    # Iterate over each row in the subset with progress bar\n",
    "    for _, row in tqdm(subset.iterrows(),\n",
    "                       total=len(subset),\n",
    "                       desc=f\"{evaluator_model} → {target_model}\",\n",
    "                       leave=False):\n",
    "        # Build prompt for depth of reasoning assessment\n",
    "        prompt = build_originality_prompt(row)\n",
    "        # Generate response using step_two function\n",
    "        generated_text = step_two(evaluator_model, prompt)\n",
    "        generated.append(generated_text)\n",
    "\n",
    "    # Store generated responses in the corresponding column\n",
    "    subsets_with_results[target_model][f'step2_{evaluator_model}'] = generated\n",
    "\n",
    "# Create list of tasks for all model pairs (evaluator vs target)\n",
    "tasks = [\n",
    "    (evaluator, target)\n",
    "    for evaluator in unique_models\n",
    "    for target in unique_models\n",
    "]\n",
    "\n",
    "# Execute evaluation tasks in parallel using ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [\n",
    "        executor.submit(evaluate_pair, evaluator, target)\n",
    "        for evaluator, target in tasks\n",
    "    ]\n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# Save the results for each target model to CSV files\n",
    "for target_model, df_result in subsets_with_results.items():\n",
    "    df_result.to_csv(f\"data/step2/partial/originality_{target_model}.csv\", index=False)\n",
    "    print(f\"Saved: originality_{target_model}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique models from the dataframe\n",
    "unique_models = df['model'].unique()\n",
    "\n",
    "# Create subsets of the dataframe for each target model\n",
    "subsets_with_results = {\n",
    "    model: df[df['model'] == model].copy()\n",
    "    for model in unique_models\n",
    "}\n",
    "\n",
    "# List of missing model pairs (evaluator → target)\n",
    "missing_pairs = [\n",
    "    (\"model_gpt_4o_mini\", \"model_gpt_4o_mini\"),\n",
    "    (\"model_gpt_4o_mini\", \"model_gpt_41_nano\"),\n",
    "    (\"model_claude_35_haiku\", \"model_gpt_4o_mini\"),\n",
    "    (\"model_gpt_4o_mini\", \"model_ds_v3\"),\n",
    "    (\"model_gpt_41_nano\", \"model_gpt_41_nano\"),\n",
    "    (\"model_gpt_41_nano\", \"model_gpt_4o_mini\"),\n",
    "    (\"model_gpt_41_nano\", \"model_grok_3_mini_beta\"),\n",
    "    (\"model_gpt_4o_mini\", \"model_claude_35_haiku\"),\n",
    "    (\"model_claude_35_haiku\", \"model_gpt_41_nano\"),\n",
    "    (\"model_claude_35_haiku\", \"model_grok_3_mini_beta\")\n",
    "]\n",
    "\n",
    "# Output directory path\n",
    "output_dir = \"data/step2/partial\"\n",
    "\n",
    "# Main evaluation function for each model pair\n",
    "def evaluate_pair(evaluator_model, target_model):\n",
    "    subset = subsets_with_results[target_model]\n",
    "    generated = []\n",
    "\n",
    "    print(f\"\\nEvaluating: {evaluator_model} → {target_model} ({len(subset)} items)\")    \n",
    "    for _, row in tqdm(subset.iterrows(), total=len(subset), desc=f\"{evaluator_model} → {target_model}\", leave=False):\n",
    "        try:\n",
    "            # Build prompt for depth of reasoning assessment\n",
    "            prompt = build_originality_prompt(row)\n",
    "            # Generate response using the recovery function\n",
    "            generated_text = step_two_recovered(evaluator_model, prompt)\n",
    "        except Exception as e:\n",
    "            # Handle errors gracefully\n",
    "            generated_text = f\"ERROR: {str(e)}\"\n",
    "        generated.append(generated_text)\n",
    "\n",
    "    # Store generated responses in the corresponding column\n",
    "    subsets_with_results[target_model][f'step2_{evaluator_model}'] = generated\n",
    "\n",
    "# Execute evaluation for each missing pair in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [\n",
    "        executor.submit(evaluate_pair, evaluator, target)\n",
    "        for evaluator, target in missing_pairs\n",
    "    ]\n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# Save each target model's results as a separate CSV to prevent overwriting\n",
    "for target_model, df_result in subsets_with_results.items():\n",
    "    output_path = os.path.join(output_dir, f\"originality_{target_model}_recovered.csv\")\n",
    "    df_result.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['originality_model_claude_35_haiku.csv', 'originality_model_claude_35_haiku_recovered.csv', 'originality_model_ds_v3.csv', 'originality_model_ds_v3_recovered.csv', 'originality_model_gpt_41_nano.csv', 'originality_model_gpt_41_nano_recovered.csv', 'originality_model_gpt_4o_mini.csv', 'originality_model_gpt_4o_mini_recovered.csv', 'originality_model_grok_3_mini_beta.csv', 'originality_model_grok_3_mini_beta_recovered.csv']\n"
     ]
    }
   ],
   "source": [
    "# Sort the list of CSV files alphabetically and print\n",
    "step2_dir = \"data/step2/partial\"\n",
    "csv_files = [f for f in os.listdir(step2_dir) if f.endswith('.csv')]\n",
    "csv_files.sort()\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 20)\n",
      "(2025, 20)\n",
      "(2025, 20)\n",
      "(2025, 20)\n",
      "(2025, 20)\n",
      "merged_all.csv salvo com shape: (10125, 20)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho para os arquivos CSV\n",
    "step2_dir = 'data/step2/partial'\n",
    "output_dir = 'data/step2/merged'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Lista de arquivos CSV na pasta (excluindo os que já são \"_recovered.csv\")\n",
    "csv_files = [f for f in os.listdir(step2_dir) if f.endswith('.csv') and not f.endswith('_recovered.csv')]\n",
    "\n",
    "# Colunas para realizar o join\n",
    "join_columns = [\n",
    "    'source', 'item', 'answer', 'r', 'model', 'prompt_type',\n",
    "    'model_answer', 'hit', 'model_alternative_answer',\n",
    "    'hit_alternative', 'alternative_response', 'justification',\n",
    "    'extra_text', 'CoT', 'cot_steps'\n",
    "]\n",
    "\n",
    "# Lista para acumular todos os merged_df\n",
    "merged_list = []\n",
    "\n",
    "for filename in csv_files:\n",
    "    original_path = os.path.join(step2_dir, filename)\n",
    "    recovered_path = os.path.join(step2_dir, filename.replace('.csv', '_recovered.csv'))\n",
    "    \n",
    "    if not os.path.exists(recovered_path):\n",
    "        print(f'Arquivo não encontrado: {recovered_path}')\n",
    "        continue\n",
    "\n",
    "    original_df = pd.read_csv(original_path)\n",
    "    recovered_df = pd.read_csv(recovered_path)\n",
    "\n",
    "    merged_df = original_df.merge(recovered_df, how='left', on=join_columns)\n",
    "\n",
    "    # Reorganize columns após 'cot_steps'\n",
    "    cols = list(merged_df.columns)\n",
    "    try:\n",
    "        cot_steps_index = cols.index('cot_steps')\n",
    "        after_cot_steps = cols[cot_steps_index + 1:]\n",
    "        sorted_after_cot_steps = sorted(after_cot_steps)\n",
    "        new_order = cols[:cot_steps_index + 1] + sorted_after_cot_steps\n",
    "        merged_df = merged_df[new_order]\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Salva o arquivo individual\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(merged_df.shape)\n",
    "\n",
    "    # Acumula no merged_all\n",
    "    merged_list.append(merged_df)\n",
    "\n",
    "# Concatena tudo no final\n",
    "merged_all = pd.concat(merged_list, ignore_index=True)\n",
    "merged_all.to_csv(os.path.join(output_dir, 'originality_model_merged_all.csv'), index=False)\n",
    "print('merged_all.csv salvo com shape:', merged_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recovery ERROR code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['source', 'item', 'answer', 'r', 'model', 'prompt_type', 'model_answer', 'hit', 'model_alternative_answer', 'hit_alternative', 'alternative_response', 'justification', 'extra_text', 'CoT', 'cot_steps', 'step2_model_claude_35_haiku', 'step2_model_ds_v3', 'step2_model_gpt_41_nano', 'step2_model_gpt_4o_mini', 'step2_model_grok_3_mini_beta']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the depth of reasoning and originality datasets\n",
    "depth_df = pd.read_csv('data/depth_of_reasoning_model_merged_all.csv').fillna(\"\")\n",
    "originality_df = pd.read_csv('data/originality_model_merged_all.csv').fillna(\"\")\n",
    "\n",
    "# Optional: Display the first few rows to verify successful loading\n",
    "#display(depth_df.head(2))\n",
    "#display(originality_df.head(2))\n",
    "\n",
    "# List all column names in the current DataFrame\n",
    "print(depth_df.columns.tolist())\n",
    "\n",
    "# Create two datasets: one with errors in specified columns, another without errors\n",
    "\n",
    "# Define the columns to check for errors\n",
    "columns_to_check = [\n",
    "    'step2_model_claude_35_haiku',\n",
    "    'step2_model_ds_v3',\n",
    "    'step2_model_gpt_41_nano',\n",
    "    'step2_model_gpt_4o_mini',\n",
    "    'step2_model_grok_3_mini_beta'\n",
    "]\n",
    "\n",
    "import re\n",
    "\n",
    "# Function to identify errors in the specified columns using regex\n",
    "def has_error(value):\n",
    "    if pd.isnull(value):\n",
    "        return False\n",
    "    value_str = str(value)\n",
    "    # Check if the string starts with 'Error' (case-insensitive)\n",
    "    if re.match(r'^ERROR', value_str, re.IGNORECASE):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Filter dataset with errors\n",
    "deep_df_with_errors = depth_df[depth_df[columns_to_check].apply(lambda row: any(has_error(val) for val in row), axis=1)]\n",
    "originality_df_with_errors = originality_df[originality_df[columns_to_check].apply(lambda row: any(has_error(val) for val in row), axis=1)]\n",
    "\n",
    "# Filter dataset without errors\n",
    "deep_df_without_errors = depth_df[~depth_df[columns_to_check].apply(lambda row: any(has_error(val) for val in row), axis=1)]\n",
    "deep_dforiginality_df_without_errors = originality_df[~originality_df[columns_to_check].apply(lambda row: any(has_error(val) for val in row), axis=1)]\n",
    "\n",
    "#display(deep_df_with_errors.head(2))\n",
    "#display(originality_df_with_errors.head(2))\n",
    "deep_df_with_errors_original = deep_df_with_errors.copy(deep=True)\n",
    "originality_df_with_errors_original = originality_df_with_errors.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recalling step2_model_claude_35_haiku: 100%|██████████| 1478/1478 [00:33<00:00, 44.78it/s]\n",
      "Recalling step2_model_claude_35_haiku: 100%|██████████| 4206/4206 [00:00<00:00, 13028.46it/s]\n",
      "Recalling step2_model_ds_v3: 100%|██████████| 1478/1478 [00:00<00:00, 12801.32it/s]\n",
      "Recalling step2_model_ds_v3: 100%|██████████| 4206/4206 [00:00<00:00, 12718.45it/s]\n",
      "Recalling step2_model_gpt_41_nano: 100%|██████████| 1478/1478 [00:00<00:00, 12816.96it/s]\n",
      "Recalling step2_model_gpt_41_nano: 100%|██████████| 4206/4206 [00:00<00:00, 12465.75it/s]\n",
      "Recalling step2_model_gpt_4o_mini: 100%|██████████| 1478/1478 [56:43<00:00,  2.30s/it] \n",
      "Recalling step2_model_gpt_4o_mini: 100%|██████████| 4206/4206 [1:53:10<00:00,  1.61s/it]  \n",
      "Recalling step2_model_grok_3_mini_beta: 100%|██████████| 1478/1478 [00:00<00:00, 9750.80it/s]\n",
      "Recalling step2_model_grok_3_mini_beta: 100%|██████████| 4206/4206 [00:00<00:00, 12825.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def recall_llm_and_update_depth(df, model_column):\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=f\"Recalling {model_column}\"):\n",
    "        if str(row[model_column]).startswith(\"ERROR\"):\n",
    "            try:\n",
    "                prompt = build_depth_of_reasoning_prompt(row)\n",
    "                model_to_use = model_column.replace('step2_', '')  # ajusta o nome do modelo\n",
    "                response = step_two_recovered(model_to_use, prompt)\n",
    "                df.at[index, model_column] = response\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                df.at[index, model_column] = f\"ERROR: {e}\"\n",
    "    return df\n",
    "\n",
    "def recall_llm_and_update_originality(df, model_column):\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=f\"Recalling {model_column}\"):\n",
    "        if str(row[model_column]).startswith(\"ERROR\"):\n",
    "            try:\n",
    "                prompt = build_originality_prompt(row)\n",
    "                model_to_use = model_column.replace('step2_', '')  # ajusta o nome do modelo\n",
    "                response = step_two_recovered(model_to_use, prompt)\n",
    "                df.at[index, model_column] = response\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                df.at[index, model_column] = f\"ERROR: {e}\"\n",
    "    return df\n",
    "\n",
    "# Iterate through the columns and apply the recall function\n",
    "for column in columns_to_check:\n",
    "    deep_df_with_errors = recall_llm_and_update_depth(deep_df_with_errors, column)\n",
    "    originality_df_with_errors = recall_llm_and_update_originality(originality_df_with_errors, column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of error occurrences: 0, 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of occurrences where any error exists in the specified columns of depth_df\n",
    "error_deep = deep_df_with_errors[deep_df_with_errors[columns_to_check].apply(lambda row: any(has_error(val) for val in row), axis=1)].shape[0]\n",
    "error_orig = originality_df_with_errors[originality_df_with_errors[columns_to_check].apply(lambda row: any(has_error(val) for val in row), axis=1)].shape[0]\n",
    "print(f\"Number of error occurrences: {error_deep}, {error_orig}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_deep = pd.concat([deep_df_without_errors, deep_df_with_errors], ignore_index=True)\n",
    "df_final_orig = pd.concat([deep_dforiginality_df_without_errors, originality_df_with_errors], ignore_index=True)\n",
    "\n",
    "# Save the concatenated dataframes as CSV files\n",
    "df_final_deep.to_csv('data/deep_recovered.csv', index=False)\n",
    "df_final_orig.to_csv('data/originality_recovered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extract from cell json - complete and tidy data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14628/1039288502.py:62: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_combined['cot_steps'] = df_combined['cot_steps'].replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>item</th>\n",
       "      <th>answer</th>\n",
       "      <th>r</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>hit</th>\n",
       "      <th>model_alternative_answer</th>\n",
       "      <th>hit_alternative</th>\n",
       "      <th>...</th>\n",
       "      <th>just_ori_claude_35_haiku</th>\n",
       "      <th>gr_ori_ds_v3</th>\n",
       "      <th>just_ori_ds_v3</th>\n",
       "      <th>gr_ori_gpt_41_nano</th>\n",
       "      <th>just_ori_gpt_41_nano</th>\n",
       "      <th>gr_ori_gpt_4o_mini</th>\n",
       "      <th>just_ori_gpt_4o_mini</th>\n",
       "      <th>gr_ori_grok_3_mini_beta</th>\n",
       "      <th>just_ori_grok_3_mini_beta</th>\n",
       "      <th>criterion_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>model_gpt_41_nano</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>The response demonstrates structured reasoning...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The response demonstrates structured reasoning...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>The response employs structured step-by-step r...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The extracted content shows some original reas...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Response shows some original phrasing and stru...</td>\n",
       "      <td>originality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>model_gpt_41_nano</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Demonstrates moderate originality through stru...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Contains some original phrasing and structured...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>The reasoning adopts a structured, step-by-ste...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>The extracted answer shows strong semantic tra...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Moderate originality from structured Chain of ...</td>\n",
       "      <td>originality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>model_gpt_41_nano</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>The response demonstrates structured reasoning...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The response demonstrates structured reasoning...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>The reasoning employs a structured, step-by-st...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>The response demonstrates strong semantic tran...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The response includes some original structurin...</td>\n",
       "      <td>originality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                               item answer  r  \\\n",
       "0    ARC  Question: Which of the following traits is mos...      A  0   \n",
       "1    ARC  Question: Which of the following traits is mos...      A  1   \n",
       "2    ARC  Question: Which of the following traits is mos...      A  2   \n",
       "\n",
       "               model prompt_type model_answer  hit model_alternative_answer  \\\n",
       "0  model_gpt_41_nano         cot            A    1                        A   \n",
       "1  model_gpt_41_nano         cot            A    1                        A   \n",
       "2  model_gpt_41_nano         cot            A    1                        A   \n",
       "\n",
       "   hit_alternative  ...                           just_ori_claude_35_haiku  \\\n",
       "0                1  ...  The response demonstrates structured reasoning...   \n",
       "1                1  ...  Demonstrates moderate originality through stru...   \n",
       "2                1  ...  The response demonstrates structured reasoning...   \n",
       "\n",
       "  gr_ori_ds_v3                                     just_ori_ds_v3  \\\n",
       "0          6.5  The response demonstrates structured reasoning...   \n",
       "1          6.0  Contains some original phrasing and structured...   \n",
       "2          6.5  The response demonstrates structured reasoning...   \n",
       "\n",
       "  gr_ori_gpt_41_nano                               just_ori_gpt_41_nano  \\\n",
       "0                7.5  The response employs structured step-by-step r...   \n",
       "1                7.5  The reasoning adopts a structured, step-by-ste...   \n",
       "2                8.2  The reasoning employs a structured, step-by-st...   \n",
       "\n",
       "  gr_ori_gpt_4o_mini                               just_ori_gpt_4o_mini  \\\n",
       "0                6.5  The extracted content shows some original reas...   \n",
       "1                7.5  The extracted answer shows strong semantic tra...   \n",
       "2                7.5  The response demonstrates strong semantic tran...   \n",
       "\n",
       "  gr_ori_grok_3_mini_beta                          just_ori_grok_3_mini_beta  \\\n",
       "0                     6.5  Response shows some original phrasing and stru...   \n",
       "1                     6.0  Moderate originality from structured Chain of ...   \n",
       "2                     6.0  The response includes some original structurin...   \n",
       "\n",
       "   criterion_y  \n",
       "0  originality  \n",
       "1  originality  \n",
       "2  originality  \n",
       "\n",
       "[3 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10125 entries, 0 to 10124\n",
      "Data columns (total 47 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   source                          10125 non-null  object \n",
      " 1   item                            10125 non-null  object \n",
      " 2   answer                          10125 non-null  object \n",
      " 3   r                               10125 non-null  int64  \n",
      " 4   model                           10125 non-null  object \n",
      " 5   prompt_type                     10125 non-null  object \n",
      " 6   model_answer                    10125 non-null  object \n",
      " 7   hit                             10125 non-null  int64  \n",
      " 8   model_alternative_answer        10125 non-null  object \n",
      " 9   hit_alternative                 10125 non-null  int64  \n",
      " 10  alternative_response            10125 non-null  object \n",
      " 11  justification                   10125 non-null  object \n",
      " 12  extra_text                      10125 non-null  object \n",
      " 13  CoT                             10125 non-null  object \n",
      " 14  cot_steps                       6750 non-null   float64\n",
      " 15  step2_model_claude_35_haiku_x   10125 non-null  object \n",
      " 16  step2_model_ds_v3_x             10125 non-null  object \n",
      " 17  step2_model_gpt_41_nano_x       10125 non-null  object \n",
      " 18  step2_model_gpt_4o_mini_x       10125 non-null  object \n",
      " 19  step2_model_grok_3_mini_beta_x  10125 non-null  object \n",
      " 20  gr_dor_claude_35_haiku          10125 non-null  float64\n",
      " 21  just_dor_claude_35_haiku        10125 non-null  object \n",
      " 22  gr_dor_ds_v3                    10125 non-null  float64\n",
      " 23  just_dor_ds_v3                  10124 non-null  object \n",
      " 24  gr_dor_gpt_41_nano              10125 non-null  float64\n",
      " 25  just_dor_gpt_41_nano            10125 non-null  object \n",
      " 26  gr_dor_gpt_4o_mini              10122 non-null  float64\n",
      " 27  just_dor_gpt_4o_mini            10124 non-null  object \n",
      " 28  gr_dor_grok_3_mini_beta         10125 non-null  float64\n",
      " 29  just_dor_grok_3_mini_beta       10125 non-null  object \n",
      " 30  criterion_x                     10125 non-null  object \n",
      " 31  step2_model_claude_35_haiku_y   10125 non-null  object \n",
      " 32  step2_model_ds_v3_y             10125 non-null  object \n",
      " 33  step2_model_gpt_41_nano_y       10125 non-null  object \n",
      " 34  step2_model_gpt_4o_mini_y       10125 non-null  object \n",
      " 35  step2_model_grok_3_mini_beta_y  10125 non-null  object \n",
      " 36  gr_ori_claude_35_haiku          10125 non-null  float64\n",
      " 37  just_ori_claude_35_haiku        10125 non-null  object \n",
      " 38  gr_ori_ds_v3                    10125 non-null  float64\n",
      " 39  just_ori_ds_v3                  10125 non-null  object \n",
      " 40  gr_ori_gpt_41_nano              10124 non-null  float64\n",
      " 41  just_ori_gpt_41_nano            10124 non-null  object \n",
      " 42  gr_ori_gpt_4o_mini              10125 non-null  float64\n",
      " 43  just_ori_gpt_4o_mini            10125 non-null  object \n",
      " 44  gr_ori_grok_3_mini_beta         10125 non-null  float64\n",
      " 45  just_ori_grok_3_mini_beta       10125 non-null  object \n",
      " 46  criterion_y                     10125 non-null  object \n",
      "dtypes: float64(11), int64(3), object(33)\n",
      "memory usage: 3.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the recovered deep data\n",
    "df_dor = pd.read_csv('data/deep_recovered.csv')\n",
    "df_dor = df_dor.fillna(\"\")  # Fill NaN values with empty string\n",
    "\n",
    "# Load the recovered originality data\n",
    "df_ori = pd.read_csv('data/originality_recovered.csv')\n",
    "df_ori = df_ori.fillna(\"\")  # Fill NaN values with empty string\n",
    "\n",
    "# Lista de colunas a processar\n",
    "columns_to_check = [\n",
    "    'step2_model_claude_35_haiku',\n",
    "    'step2_model_ds_v3',\n",
    "    'step2_model_gpt_41_nano',\n",
    "    'step2_model_gpt_4o_mini',\n",
    "    'step2_model_grok_3_mini_beta'\n",
    "]\n",
    "\n",
    "# Funções auxiliares com regex\n",
    "def extract_field_regex(text, field):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    pattern_number = rf'\"{field}\"\\s*:\\s*([0-9]+(?:\\.[0-9]+)?)'\n",
    "    pattern_string = rf'\"{field}\"\\s*:\\s*\"([^\"]+)\"'\n",
    "    \n",
    "    match_number = re.search(pattern_number, text)\n",
    "    if match_number:\n",
    "        return float(match_number.group(1))\n",
    "    \n",
    "    match_string = re.search(pattern_string, text)\n",
    "    if match_string:\n",
    "        return match_string.group(1)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Aplica a extração para cada coluna\n",
    "for col in columns_to_check:\n",
    "    model = col.replace('step2_model_', '')\n",
    "\n",
    "    # df_dor: extrai depth_of_reasoning e justification\n",
    "    df_dor[f'gr_dor_{model}'] = df_dor[col].apply(lambda x: extract_field_regex(x, 'depth_of_reasoning'))\n",
    "    df_dor[f'just_dor_{model}'] = df_dor[col].apply(lambda x: extract_field_regex(x, 'depth_of_reasoning_justification'))\n",
    "\n",
    "    # df_ori: extrai originality e justification\n",
    "    df_ori[f'gr_ori_{model}'] = df_ori[col].apply(lambda x: extract_field_regex(x, 'originality'))\n",
    "    df_ori[f'just_ori_{model}'] = df_ori[col].apply(lambda x: extract_field_regex(x, 'originality_justification'))\n",
    "\n",
    "# Adiciona a coluna que identifica a origem da base\n",
    "df_dor['criterion'] = 'depth of reasoning'\n",
    "df_ori['criterion'] = 'originality'\n",
    "\n",
    "df_combined = df_dor.merge(df_ori, on=['source', 'item', 'answer', 'r', 'model', 'prompt_type', 'model_answer',\n",
    "                                        'hit', 'model_alternative_answer', 'hit_alternative',\n",
    "                                        'alternative_response', 'justification', 'extra_text', 'CoT',\n",
    "                                        'cot_steps'], how='left')\n",
    "\n",
    "\n",
    "# Substituir strings vazias ou espaços por NaN\n",
    "df_combined['cot_steps'] = df_combined['cot_steps'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Converter para numérico (valores inválidos serão convertidos em NaN)\n",
    "df_combined['cot_steps'] = pd.to_numeric(df_combined['cot_steps'], errors='coerce')\n",
    "\n",
    "df_combined.to_parquet('data/tidy_data_2_aed_model.parquet', index=False)\n",
    "\n",
    "display(df_combined.head(3))\n",
    "print(df_combined.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source', 'item', 'answer', 'r', 'model', 'prompt_type', 'model_answer',\n",
      "       'hit', 'model_alternative_answer', 'hit_alternative',\n",
      "       'alternative_response', 'justification', 'extra_text', 'CoT',\n",
      "       'cot_steps', 'step2_model_claude_35_haiku_x', 'step2_model_ds_v3_x',\n",
      "       'step2_model_gpt_41_nano_x', 'step2_model_gpt_4o_mini_x',\n",
      "       'step2_model_grok_3_mini_beta_x', 'gr_dor_claude_35_haiku',\n",
      "       'just_dor_claude_35_haiku', 'gr_dor_ds_v3', 'just_dor_ds_v3',\n",
      "       'gr_dor_gpt_41_nano', 'just_dor_gpt_41_nano', 'gr_dor_gpt_4o_mini',\n",
      "       'just_dor_gpt_4o_mini', 'gr_dor_grok_3_mini_beta',\n",
      "       'just_dor_grok_3_mini_beta', 'criterion_x',\n",
      "       'step2_model_claude_35_haiku_y', 'step2_model_ds_v3_y',\n",
      "       'step2_model_gpt_41_nano_y', 'step2_model_gpt_4o_mini_y',\n",
      "       'step2_model_grok_3_mini_beta_y', 'gr_ori_claude_35_haiku',\n",
      "       'just_ori_claude_35_haiku', 'gr_ori_ds_v3', 'just_ori_ds_v3',\n",
      "       'gr_ori_gpt_41_nano', 'just_ori_gpt_41_nano', 'gr_ori_gpt_4o_mini',\n",
      "       'just_ori_gpt_4o_mini', 'gr_ori_grok_3_mini_beta',\n",
      "       'just_ori_grok_3_mini_beta', 'criterion_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_combined.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>item</th>\n",
       "      <th>answer</th>\n",
       "      <th>r</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>hit</th>\n",
       "      <th>model_alternative_answer</th>\n",
       "      <th>hit_alternative</th>\n",
       "      <th>...</th>\n",
       "      <th>justif_claude_35_haiku</th>\n",
       "      <th>grade_ds_v3</th>\n",
       "      <th>justif_ds_v3</th>\n",
       "      <th>grade_gpt_41_nano</th>\n",
       "      <th>justif_gpt_41_nano</th>\n",
       "      <th>grade_gpt_4o_mini</th>\n",
       "      <th>justif_gpt_4o_mini</th>\n",
       "      <th>grade_grok_3_mini_beta</th>\n",
       "      <th>justif_grok_3_mini_beta</th>\n",
       "      <th>criterion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>model_gpt_41_nano</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>The reasoning demonstrates a systematic, multi...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>The reasoning is sound and structured, with a ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The reasoning demonstrates a multi-step and la...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The reasoning demonstrates multi-step, layered...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>The extracted chain of thought exhibits multi-...</td>\n",
       "      <td>depth of reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which of the following traits is mos...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>model_gpt_41_nano</td>\n",
       "      <td>cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>The reasoning demonstrates a structured, multi...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The extracted chain of thought demonstrates a ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The reasoning demonstrates a multi-step, layer...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The reasoning exhibits multi-step, layered inf...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The extracted chain of thought demonstrates mu...</td>\n",
       "      <td>depth of reasoning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                               item answer  r  \\\n",
       "0    ARC  Question: Which of the following traits is mos...      A  0   \n",
       "1    ARC  Question: Which of the following traits is mos...      A  1   \n",
       "\n",
       "               model prompt_type model_answer  hit model_alternative_answer  \\\n",
       "0  model_gpt_41_nano         cot            A    1                        A   \n",
       "1  model_gpt_41_nano         cot            A    1                        A   \n",
       "\n",
       "   hit_alternative  ...                             justif_claude_35_haiku  \\\n",
       "0                1  ...  The reasoning demonstrates a systematic, multi...   \n",
       "1                1  ...  The reasoning demonstrates a structured, multi...   \n",
       "\n",
       "  grade_ds_v3                                       justif_ds_v3  \\\n",
       "0         8.0  The reasoning is sound and structured, with a ...   \n",
       "1         9.0  The extracted chain of thought demonstrates a ...   \n",
       "\n",
       "  grade_gpt_41_nano                                 justif_gpt_41_nano  \\\n",
       "0               9.0  The reasoning demonstrates a multi-step and la...   \n",
       "1               9.0  The reasoning demonstrates a multi-step, layer...   \n",
       "\n",
       "  grade_gpt_4o_mini                                 justif_gpt_4o_mini  \\\n",
       "0               9.0  The reasoning demonstrates multi-step, layered...   \n",
       "1               9.0  The reasoning exhibits multi-step, layered inf...   \n",
       "\n",
       "  grade_grok_3_mini_beta                            justif_grok_3_mini_beta  \\\n",
       "0                    9.5  The extracted chain of thought exhibits multi-...   \n",
       "1                    9.0  The extracted chain of thought demonstrates mu...   \n",
       "\n",
       "            criterion  \n",
       "0  depth of reasoning  \n",
       "1  depth of reasoning  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>item</th>\n",
       "      <th>answer</th>\n",
       "      <th>r</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>hit</th>\n",
       "      <th>model_alternative_answer</th>\n",
       "      <th>hit_alternative</th>\n",
       "      <th>...</th>\n",
       "      <th>justif_claude_35_haiku</th>\n",
       "      <th>grade_ds_v3</th>\n",
       "      <th>justif_ds_v3</th>\n",
       "      <th>grade_gpt_41_nano</th>\n",
       "      <th>justif_gpt_41_nano</th>\n",
       "      <th>grade_gpt_4o_mini</th>\n",
       "      <th>justif_gpt_4o_mini</th>\n",
       "      <th>grade_grok_3_mini_beta</th>\n",
       "      <th>justif_grok_3_mini_beta</th>\n",
       "      <th>criterion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20248</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which two systems primarily function...</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>model_ds_v3</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>The response demonstrates strong analytical re...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Strong semantic transformation with novel stru...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>The response closely mirrors the input's struc...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response retains significant elements from...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Strong semantic transformation with structured...</td>\n",
       "      <td>originality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20249</th>\n",
       "      <td>ARC</td>\n",
       "      <td>Question: Which two systems primarily function...</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>model_ds_v3</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>The response demonstrates strong originality t...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>The response demonstrates strong semantic tran...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The response mainly mirrors the input's struct...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The extracted content demonstrates some degree...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The response features structured step-by-step ...</td>\n",
       "      <td>originality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                               item answer  r  \\\n",
       "20248    ARC  Question: Which two systems primarily function...      D  2   \n",
       "20249    ARC  Question: Which two systems primarily function...      D  4   \n",
       "\n",
       "             model  prompt_type model_answer  hit model_alternative_answer  \\\n",
       "20248  model_ds_v3  adversarial            E    0                        E   \n",
       "20249  model_ds_v3  adversarial            E    0                        E   \n",
       "\n",
       "       hit_alternative  ...  \\\n",
       "20248                0  ...   \n",
       "20249                0  ...   \n",
       "\n",
       "                                  justif_claude_35_haiku grade_ds_v3  \\\n",
       "20248  The response demonstrates strong analytical re...         7.5   \n",
       "20249  The response demonstrates strong originality t...         8.5   \n",
       "\n",
       "                                            justif_ds_v3 grade_gpt_41_nano  \\\n",
       "20248  Strong semantic transformation with novel stru...               2.5   \n",
       "20249  The response demonstrates strong semantic tran...               2.0   \n",
       "\n",
       "                                      justif_gpt_41_nano grade_gpt_4o_mini  \\\n",
       "20248  The response closely mirrors the input's struc...               5.0   \n",
       "20249  The response mainly mirrors the input's struct...               6.5   \n",
       "\n",
       "                                      justif_gpt_4o_mini  \\\n",
       "20248  The response retains significant elements from...   \n",
       "20249  The extracted content demonstrates some degree...   \n",
       "\n",
       "      grade_grok_3_mini_beta  \\\n",
       "20248                    8.0   \n",
       "20249                    7.0   \n",
       "\n",
       "                                 justif_grok_3_mini_beta    criterion  \n",
       "20248  Strong semantic transformation with structured...  originality  \n",
       "20249  The response features structured step-by-step ...  originality  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "df_combined = pd.concat([df_dor, df_ori], ignore_index=True)\n",
    "csv_path = 'data/tidy_data_2_aed_model.csv'\n",
    "tar_path = 'data/tidy_data_2_aed_model.tar.xz'\n",
    "\n",
    "# Save CSV\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "\n",
    "# Compress to tar.xz\n",
    "with tarfile.open(tar_path, \"w:xz\") as tar:\n",
    "    tar.add(csv_path, arcname=os.path.basename(csv_path))\n",
    "\n",
    "# Remove the original CSV file\n",
    "os.remove(csv_path)\n",
    "display(df_combined.head(2))\n",
    "display(df_combined.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classical Metrics Report - Traditional Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Overall Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.8417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall  F1-Score\n",
       "0    0.8251       0.86  0.8251    0.8417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Overall Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>125</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1872</td>\n",
       "      <td>130</td>\n",
       "      <td>31</td>\n",
       "      <td>179</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>183</td>\n",
       "      <td>2201</td>\n",
       "      <td>103</td>\n",
       "      <td>85</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>74</td>\n",
       "      <td>2333</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>69</td>\n",
       "      <td>89</td>\n",
       "      <td>1948</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        125     A     B     C     D    E\n",
       "     0    0     0     0     0     0    0\n",
       "125  0    0     0     0     0     0    0\n",
       "A    1    0  1872   130    31   179  112\n",
       "B    0    5   183  2201   103    85   48\n",
       "C    1    0   207    74  2333    58  102\n",
       "D    1    0   183    69    89  1948  110\n",
       "E    0    0     0     0     0     0    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Aggregated Metrics by Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro_Precision</th>\n",
       "      <th>Macro_Recall</th>\n",
       "      <th>Macro_F1</th>\n",
       "      <th>Weighted_Precision</th>\n",
       "      <th>Weighted_Recall</th>\n",
       "      <th>Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_gpt_41_nano</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.5787</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.8709</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.8424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_ds_v3</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.6749</td>\n",
       "      <td>0.6934</td>\n",
       "      <td>0.8938</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.8689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_gpt_4o_mini</td>\n",
       "      <td>0.7323</td>\n",
       "      <td>0.4391</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>0.4254</td>\n",
       "      <td>0.7736</td>\n",
       "      <td>0.7323</td>\n",
       "      <td>0.7472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_grok_3_mini_beta</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_claude_35_haiku</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>0.8501</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.8438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Macro_Precision  Macro_Recall  Macro_F1  \\\n",
       "0       model_gpt_41_nano    0.8163           0.5787        0.5426    0.5598   \n",
       "1             model_ds_v3    0.8454           0.7131        0.6749    0.6934   \n",
       "2       model_gpt_4o_mini    0.7323           0.4391        0.4186    0.4254   \n",
       "3  model_grok_3_mini_beta    0.8933           0.7322        0.7144    0.7226   \n",
       "4   model_claude_35_haiku    0.8380           0.6779        0.6696    0.6736   \n",
       "\n",
       "   Weighted_Precision  Weighted_Recall  Weighted_F1  \n",
       "0              0.8709           0.8163       0.8424  \n",
       "1              0.8938           0.8454       0.8689  \n",
       "2              0.7736           0.7323       0.7472  \n",
       "3              0.9185           0.8933       0.9050  \n",
       "4              0.8501           0.8380       0.8438  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Class-level F1-Score Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_gpt_41_nano</th>\n",
       "      <th>model_ds_v3</th>\n",
       "      <th>model_gpt_4o_mini</th>\n",
       "      <th>model_grok_3_mini_beta</th>\n",
       "      <th>model_claude_35_haiku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.7922</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>0.6961</td>\n",
       "      <td>0.8443</td>\n",
       "      <td>0.7911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.8661</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8969</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.8706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.8146</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.7169</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.8462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_gpt_41_nano  model_ds_v3  model_gpt_4o_mini  \\\n",
       "                0.0000       0.0000             0.0000   \n",
       "125             0.0000       0.0000             0.0000   \n",
       "A               0.7922       0.8141             0.6961   \n",
       "B               0.8661       0.8948             0.7783   \n",
       "C               0.8862       0.8969             0.7868   \n",
       "D               0.8146       0.8614             0.7169   \n",
       "E               0.0000       0.0000             0.0000   \n",
       "\n",
       "     model_grok_3_mini_beta  model_claude_35_haiku  \n",
       "                     0.0000                 0.0000  \n",
       "125                  0.0000                 0.0000  \n",
       "A                    0.8443                 0.7911  \n",
       "B                    0.9176                 0.8602  \n",
       "C                    0.9320                 0.8706  \n",
       "D                    0.9190                 0.8462  \n",
       "E                    0.0000                 0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Friedman Test on Class-level F1-Scores:\n",
      "  χ² = 29.631, p = 0.0000\n",
      "🔹 Nemenyi Post-hoc Test (p < 0.05):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916448</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.548529</td>\n",
       "      <td>0.997194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252294</td>\n",
       "      <td>0.961612</td>\n",
       "      <td>0.761079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.252294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.916448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.548529</td>\n",
       "      <td>0.961612</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.339541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997194</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.916448</td>\n",
       "      <td>0.339541</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  1.000000  0.916448  0.761079  0.548529  0.997194\n",
       "1  0.916448  1.000000  0.252294  0.961612  0.761079\n",
       "2  0.761079  0.252294  1.000000  0.053284  0.916448\n",
       "3  0.548529  0.961612  0.053284  1.000000  0.339541\n",
       "4  0.997194  0.761079  0.916448  0.339541  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Dunn's Test with Benjamini-Hochberg correction:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433135</td>\n",
       "      <td>0.285857</td>\n",
       "      <td>0.643544</td>\n",
       "      <td>0.074970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.433135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901056</td>\n",
       "      <td>0.901056</td>\n",
       "      <td>0.007098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.285857</td>\n",
       "      <td>0.901056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710503</td>\n",
       "      <td>0.005159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013296</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>0.643544</td>\n",
       "      <td>0.901056</td>\n",
       "      <td>0.710503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7\n",
       "1  1.000000  1.000000  0.074970  0.007098  0.005159  0.013296  1.000000\n",
       "2  1.000000  1.000000  0.074970  0.007098  0.005159  0.013296  1.000000\n",
       "3  0.074970  0.074970  1.000000  0.433135  0.285857  0.643544  0.074970\n",
       "4  0.007098  0.007098  0.433135  1.000000  0.901056  0.901056  0.007098\n",
       "5  0.005159  0.005159  0.285857  0.901056  1.000000  0.710503  0.005159\n",
       "6  0.013296  0.013296  0.643544  0.901056  0.710503  1.000000  0.013296\n",
       "7  1.000000  1.000000  0.074970  0.007098  0.005159  0.013296  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Holm-Bonferroni method:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514081</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.015476</td>\n",
       "      <td>0.085476</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514081</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.015476</td>\n",
       "      <td>0.085476</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.514081</td>\n",
       "      <td>0.514081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015476</td>\n",
       "      <td>0.015476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.085476</td>\n",
       "      <td>0.085476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514081</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.015476</td>\n",
       "      <td>0.085476</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7\n",
       "1  1.000000  1.000000  0.514081  0.036502  0.015476  0.085476  1.000000\n",
       "2  1.000000  1.000000  0.514081  0.036502  0.015476  0.085476  1.000000\n",
       "3  0.514081  0.514081  1.000000  1.000000  1.000000  1.000000  0.514081\n",
       "4  0.036502  0.036502  1.000000  1.000000  1.000000  1.000000  0.036502\n",
       "5  0.015476  0.015476  1.000000  1.000000  1.000000  1.000000  0.015476\n",
       "6  0.085476  0.085476  1.000000  1.000000  1.000000  1.000000  0.085476\n",
       "7  1.000000  1.000000  0.514081  0.036502  0.015476  0.085476  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_gpt_41_nano' 'model_ds_v3' 'model_gpt_4o_mini'\n",
      " 'model_grok_3_mini_beta' 'model_claude_35_haiku']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_parquet('data/tidy_data_2_aed_model.parquet')\n",
    "\n",
    "# --- Overall metrics ---\n",
    "y_true = df['answer'].to_numpy()\n",
    "y_pred = df['model_answer'].to_numpy()\n",
    "valid = ~pd.isna(y_true) & ~pd.isna(y_pred)\n",
    "y_true = y_true[valid]\n",
    "y_pred = y_pred[valid]\n",
    "\n",
    "overall_metrics = {\n",
    "    \"Accuracy\": [round(accuracy_score(y_true, y_pred), 4)],\n",
    "    \"Precision\": [round(precision_score(y_true, y_pred, average='weighted', zero_division=0), 4)],\n",
    "    \"Recall\": [round(recall_score(y_true, y_pred, average='weighted', zero_division=0), 4)],\n",
    "    \"F1-Score\": [round(f1_score(y_true, y_pred, average='weighted', zero_division=0), 4)]\n",
    "}\n",
    "\n",
    "print(\"🔹 Overall Metrics:\")\n",
    "display(pd.DataFrame(overall_metrics))\n",
    "\n",
    "# --- Confusion matrix ---\n",
    "labels_all = sorted(list(set(y_true) | set(y_pred)))\n",
    "cm = pd.DataFrame(confusion_matrix(y_true, y_pred, labels=labels_all), index=labels_all, columns=labels_all)\n",
    "print(\"🔹 Overall Confusion Matrix:\")\n",
    "display(cm)\n",
    "\n",
    "# --- Aggregated metrics by model ---\n",
    "print(\"🔹 Aggregated Metrics by Model:\")\n",
    "\n",
    "model_metrics = []\n",
    "model_names = df['model'].unique()\n",
    "\n",
    "for model in model_names:\n",
    "    model_data = df[df['model'] == model]\n",
    "    yt = model_data['answer'].to_numpy()\n",
    "    yp = model_data['model_answer'].to_numpy()\n",
    "    valid = ~pd.isna(yt) & ~pd.isna(yp)\n",
    "    yt = yt[valid]\n",
    "    yp = yp[valid]\n",
    "\n",
    "    if len(yt) == 0:\n",
    "        continue\n",
    "\n",
    "    report = classification_report(yt, yp, output_dict=True, zero_division=0)\n",
    "\n",
    "    row = {\n",
    "        \"Model\": model,\n",
    "        \"Accuracy\": round(report.get(\"accuracy\", np.nan), 4),\n",
    "        \"Macro_Precision\": round(report[\"macro avg\"][\"precision\"], 4),\n",
    "        \"Macro_Recall\": round(report[\"macro avg\"][\"recall\"], 4),\n",
    "        \"Macro_F1\": round(report[\"macro avg\"][\"f1-score\"], 4),\n",
    "        \"Weighted_Precision\": round(report[\"weighted avg\"][\"precision\"], 4),\n",
    "        \"Weighted_Recall\": round(report[\"weighted avg\"][\"recall\"], 4),\n",
    "        \"Weighted_F1\": round(report[\"weighted avg\"][\"f1-score\"], 4)\n",
    "    }\n",
    "\n",
    "    model_metrics.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(model_metrics)\n",
    "display(df_summary)\n",
    "\n",
    "# --- F1 matrix per class ---\n",
    "print(\"🔹 Class-level F1-Score Matrix:\")\n",
    "\n",
    "f1_matrix = []\n",
    "\n",
    "for label in labels_all:\n",
    "    f1_row = []\n",
    "    for model in model_names:\n",
    "        data = df[df['model'] == model]\n",
    "        yt = data['answer'].to_numpy()\n",
    "        yp = data['model_answer'].to_numpy()\n",
    "        valid = ~pd.isna(yt) & ~pd.isna(yp)\n",
    "        yt = yt[valid]\n",
    "        yp = yp[valid]\n",
    "\n",
    "        if len(yt) == 0:\n",
    "            f1_row.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        report = classification_report(yt, yp, output_dict=True, zero_division=0)\n",
    "        f1 = report.get(label, {}).get('f1-score', 0.0)\n",
    "        f1_row.append(round(f1, 4))\n",
    "\n",
    "    f1_matrix.append(f1_row)\n",
    "\n",
    "f1_scores = np.array(f1_matrix)\n",
    "df_f1_matrix = pd.DataFrame(f1_scores, index=labels_all, columns=model_names)\n",
    "display(df_f1_matrix)\n",
    "\n",
    "# --- Filter valid models ---\n",
    "f1_scores_clean = np.array(f1_scores)\n",
    "valid_columns = ~np.isnan(f1_scores_clean).any(axis=0)\n",
    "f1_scores_clean = f1_scores_clean[:, valid_columns]\n",
    "valid_model_names = np.array(model_names)[valid_columns]\n",
    "\n",
    "# --- Friedman test ---\n",
    "print(\"🔹 Friedman Test on Class-level F1-Scores:\")\n",
    "stat, p = stats.friedmanchisquare(*f1_scores_clean)\n",
    "print(f\"  χ² = {stat:.3f}, p = {p:.4f}\")\n",
    "\n",
    "# --- Nemenyi post-hoc test ---\n",
    "if p < 0.05:\n",
    "    print(\"🔹 Nemenyi Post-hoc Test (p < 0.05):\")\n",
    "    nemenyi_result = sp.posthoc_nemenyi_friedman(f1_scores_clean)\n",
    "    display(nemenyi_result)\n",
    "\n",
    "# --- Dunn's Test with Benjamini-Hochberg correction ---\n",
    "if p < 0.05:\n",
    "    print(\"🔹 Dunn's Test with Benjamini-Hochberg correction:\")\n",
    "    try:\n",
    "        dunn_result = sp.posthoc_dunn(f1_scores_clean, p_adjust='fdr_bh')  # Updated method\n",
    "        display(dunn_result)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in Dunn's Test: {e}\")\n",
    "\n",
    "# --- Holm-Bonferroni method ---\n",
    "if p < 0.05:\n",
    "    print(\"🔹 Holm-Bonferroni method:\")\n",
    "    try:\n",
    "        holm_result = sp.posthoc_dunn(f1_scores_clean, p_adjust='holm')  # Use Dunn's test with Holm adjustment\n",
    "        display(holm_result)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in Holm-Bonferroni method: {e}\")\n",
    "\n",
    "print(model_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
